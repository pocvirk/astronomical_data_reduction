{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figures interactive:\n",
    "%matplotlib notebook \n",
    "# import library containing image reduction tools for this class\n",
    "from image_reduction_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets look at something pretty just to get the hang of how to display fits images in python\n",
    "files=glob.glob('../../data/photo/M1/p*f1.fits')\n",
    "data=read_raw_image(files[1])\n",
    "plt.figure(figsize=(8,8))\n",
    "# experiment with different scalings:\n",
    "# linear\n",
    "#plt.imshow(data,cmap=cm.gray,norm=None,origin='lower',aspect='auto')\n",
    "# log\n",
    "plt.imshow(data,cmap=cm.gray,norm=LogNorm(),origin='lower',aspect='auto')\n",
    "# the origin='lower' option is to have the right orientation.\n",
    "# it may be different with the most recent camera settings. TBD\n",
    "plt.show()\n",
    "# Noice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this? \n",
    "# lets have a look at the dynamics of the image!\n",
    "bins=np.linspace(0.,65000.,200)\n",
    "plt.figure(figsize=(8,5))\n",
    "h,bins=np.histogram(data.flatten(),bins)\n",
    "plt.plot(bins[:-1],h)\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.title('Pixels histogram')\n",
    "plt.xlabel('ADU')\n",
    "plt.ylabel('counts')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# discuss the different regimes in the hitogram: \n",
    "# 1 - what is the large population of darkest pixels?\n",
    "# 2 - what is the small population of brightest pixels?\n",
    "# 3 - Where in this plot lives the nebulosity of interest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEADERS! Getting information about the exposures is a vital skill!\n",
    "# have a look at the header of the files for M1\n",
    "files=glob.glob('../../data/photo/M1/p*f1.fits')\n",
    "print_header(files[0],l=1)\n",
    "#for file in files:\n",
    "#    print(file)\n",
    "#    print_header(file,keywords_list=['OBJECT'],l=0) # NOTE: relevant keyword to print may change depending on camera software setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's start a proper image reduction.\n",
    "# We will need the master bias and the master flat first.\n",
    "# Let's make a bias\n",
    "# where is the data?\n",
    "files=glob.glob('../../data/photo/offsets/p*.fits')\n",
    "data=read_raw_image(files[4])\n",
    "# what does it look like?\n",
    "plt.figure(figsize=(8,8))\n",
    "# setup the cuts of the image\n",
    "vmin,vmax=get_scaling(data)\n",
    "plt.imshow(data,cmap=cm.gray,vmin=vmin,vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# What are all these white dots? do they appear in all images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's try to make a master_bias, that requires medianning the 5 offset files\n",
    "# first lets get some stats for the images:\n",
    "files=glob.glob('../../data/photo/offsets/p*.fits')\n",
    "\n",
    "print('filename,','Npix','avg,','rms,','min,','max')\n",
    "for file in files:\n",
    "    stats=get_stats(file)\n",
    "    print(stats)\n",
    "    \n",
    "# whats' strange with these numbers?\n",
    "# Do the stats of the pixels follow a classical gaussian distribution law?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# MASTER_BIAS\n",
    "##############\n",
    "# NOW compute the median of the 5 bias and store that into master_bias\n",
    "files=glob.glob('../../data/photo/offsets/p*.fits')\n",
    "nfiles=len(files)\n",
    "data,header_ori=read_raw_image(files[0],get_header=1)\n",
    "nx,ny=np.shape(data)\n",
    "datastore=np.full((nx,ny,nfiles),0.)\n",
    "# store individual images into an array\n",
    "for i in range(nfiles):\n",
    "    datastore[:,:,i]=read_raw_image(files[i])\n",
    "# compute median of nfiles images\n",
    "result=np.median(datastore,axis=2)\n",
    "target_file='../../masters/photo/master_bias.fits'\n",
    "# update the OBJECT field of header\n",
    "header=header_ori\n",
    "header['OBJECT']='MASTER_BIAS'\n",
    "# write to file\n",
    "write_fits_image(target_file,result,header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whats the new stats? Any improvement?\n",
    "master_bias_file='../../masters/photo/master_bias.fits'\n",
    "master_bias,header1=read_raw_image(master_bias_file,get_header=1)\n",
    "print('MASTER_BIAS')\n",
    "print(get_stats(master_bias_file))\n",
    "print('individual biases')\n",
    "for file in files:\n",
    "    print(get_stats(file))\n",
    "\n",
    "# yay stats of master_bias look much better!!\n",
    "\n",
    "    \n",
    "#How does it look?\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(master_bias,cmap=cm.gray)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make a flat!\n",
    "files=glob.glob('../../data/photo/flats/B/p*.fits')\n",
    "nfiles=len(files)\n",
    "# what does it look like?\n",
    "data=read_raw_image(files[0])\n",
    "plot_image(data)\n",
    "# discuss the various structures we can see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the stats of the flats:\n",
    "files=glob.glob('../../data/photo/flats/B/p*.fits')\n",
    "for file in files:\n",
    "    print(get_stats(file))\n",
    "# What differences with the bias stats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the central line of each flat:\n",
    "files=glob.glob('../../data/photo/flats/V/p*.fits')\n",
    "#files=glob.glob('../data/photo/offsets/p*.fits')\n",
    "plt.figure(figsize=(8,5))\n",
    "iline=511\n",
    "for file in files:\n",
    "    data=read_raw_image(file)\n",
    "    plt.plot(data[iline,:],label=file)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# what do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the master_bias from each flat, then compute the normalized flats, where each flat is divided by its median:\n",
    "files=glob.glob('../../data/photo/flats/V/p*.fits')\n",
    "for file in files:\n",
    "    data,header=read_raw_image(file,get_header=1)\n",
    "    print(np.median(data))\n",
    "    bias=read_raw_image('../../masters/photo/master_bias.fits')\n",
    "    data=data-bias # Bias subtraction!\n",
    "    data=data/np.median(data) # rescaling so that median(data)=1\n",
    "    newfile=file+'.norm'\n",
    "    write_fits_image(newfile,data,header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot these normalized flats:\n",
    "# plot the central line of each flat:\n",
    "files=glob.glob('../../data/photo/flats/V/p*.fits.norm')\n",
    "plt.figure(figsize=(8,5))\n",
    "iline=511\n",
    "for file in files:\n",
    "    data=read_raw_image(file)\n",
    "    plt.plot(data[iline,:],label=file)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then median the normalized flats to get the master_flat in the considered filter\n",
    "nfiles=len(files)\n",
    "data,header_ori=read_raw_image(files[0],get_header=1)\n",
    "nx,ny=np.shape(data)\n",
    "datastore=np.full((nx,ny,nfiles),0.)\n",
    "# store individual images into an array\n",
    "for i in range(nfiles):\n",
    "    datastore[:,:,i]=read_raw_image(files[i])\n",
    "    \n",
    "# compute median of nfiles images\n",
    "result=np.median(datastore,axis=2)\n",
    "target_file='../../masters/photo/master_flat_V.fits'\n",
    "# update the OBJECT field of header (its not mandatory but will help when\n",
    "# we try to make sense of / analyse the data / its very late / we did not sleep much\n",
    "# / and everybody is tired)\n",
    "header=header_ori\n",
    "header['OBJECT']='MASTER_FLAT'\n",
    "# write to file\n",
    "write_fits_image(target_file,result,header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot normed flats as above and overplot master\n",
    "files=glob.glob('../../data/photo/flats/V/p*.fits.norm')\n",
    "plt.figure(figsize=(8,5))\n",
    "iline=511\n",
    "offset=0\n",
    "for file in files:\n",
    "    data=read_raw_image(file)\n",
    "    plt.plot(data[iline,:]+offset,label=file)\n",
    "    offset=offset#+0.05\n",
    "\n",
    "data=read_raw_image('../../masters/photo/master_flat_V.fits')\n",
    "plt.plot(data[iline,:]+offset,label='master')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reduce the observed images:\n",
    "# 1=> subtract bias\n",
    "# 2=> divide by flat WITH THE CORRESPONDING FILTER!!\n",
    "files=glob.glob('../../data/photo/M1/p439*.fits')\n",
    "filter_target='V Cousins'\n",
    "nfiles=len(files)\n",
    "for file in files:\n",
    "    data,header=read_raw_image(file,get_header=1)\n",
    "    filter_obs=header['FLTRNM']\n",
    "    if(filter_obs.find(filter_target)>=0): # this checks that the filters match\n",
    "        print('reducing ',file, filter_obs)\n",
    "        bias=read_raw_image('../../masters/photo/master_bias.fits')\n",
    "        master_flat=read_raw_image('../../masters/photo/master_flat_V.fits')\n",
    "        # THE IMPORTANT, KEY PART!!!\n",
    "        ##########################\n",
    "        reduced=(data-bias)/master_flat\n",
    "        ##########################\n",
    "        reduced_file=file+'.reduced'\n",
    "        write_fits_image(reduced_file,reduced,header)\n",
    "\n",
    "# do this for each filter or automatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now redo the steps for the Halpha, OIII and B filters of M1\n",
    "# OR DO a completely different objct, e.g. NGC2392\n",
    "# => generate master_flat for each filter\n",
    "# => reduce all Halpha, OIII and B images of M1 (i.e. subtract master_bias, divide by master_flat)\n",
    "# Then lets RGB compose M1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
