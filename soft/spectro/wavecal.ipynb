{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# => makes the plot interactive\n",
    "%matplotlib notebook \n",
    "# inline makes the plots static\n",
    "#%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "import warnings\n",
    "# filter astropy warning on fits headers\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "from spectro_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the lamp spectrum\n",
    "fits_file = '../../data/t152_spectro/lamp_thar/p67507.fits'\n",
    "xaxis,data=read_raw_spectrum(fits_file)\n",
    "spectrum=data\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(data)\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('ADU')\n",
    "plt.title('lamp spectrum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find peaks in the spectrum\n",
    "fits_file = '../../data/t152_spectro/lamp_thar/p67507.fits'\n",
    "xaxis,data=read_raw_spectrum(fits_file)\n",
    "spectrum=data\n",
    "print(len(xaxis))\n",
    "# Find peaks in the spectrum\n",
    "peaks, _ = find_peaks(data, height=5000.)  # You can adjust the 'height' threshold\n",
    "# NB: 'fiducial value': height=5000\n",
    "\n",
    "# Get the centroid (x-value) of each peak\n",
    "centroid_x_values = peaks\n",
    "# Positions in pixels of the peaks\n",
    "print(peaks)\n",
    "\n",
    "# Plot the spectrum and mark the centroids\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(data)\n",
    "plt.plot(centroid_x_values, data[peaks], 'ro', label='Max')\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('Flux')\n",
    "plt.title('Spectrum with peaks and lines')\n",
    "plt.grid(True)\n",
    "\n",
    "# Positions of the peaks in pixels\n",
    "print('line peak centers')\n",
    "print(peaks)\n",
    "# Do you think the peaks positions are representative of the line center?\n",
    "# What is the precision on the line center?\n",
    "# is that good enough?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice, now in order to improve the precision on the line centers,\n",
    "# let's fit each detected peak with a gaussian to get a better centroid position\n",
    "# generate first_guess for the fitting routine\n",
    "# The method below just makes up credible values for a triplet (intensity, centre, width) for each line\n",
    "# (~credible) using the peaks detected \n",
    "# and concatenates all that into a large vector first_guess\n",
    "first_guess=generate_first_guess(peaks)\n",
    "#print(first_guess)\n",
    "\n",
    "# fit the lamp spectrum as a sum of gaussian lines using curve_fit and our first guess\n",
    "params, covariance = curve_fit(gaussian, xaxis, data, p0=first_guess)\n",
    "#print(np.shape(covariance))\n",
    "# Reshape params into a 2D array (N, 3) for readability\n",
    "num_peaks = len(params) // 3\n",
    "print('num_peaks',num_peaks)\n",
    "params = np.array(params).reshape((num_peaks, 3))\n",
    "allamps=params[:,0]\n",
    "allcens=params[:,1] # => THIS ARRAY HAS THE FITTED GAUSSIAN CENTROILDS OF THE LINES\n",
    "allwids=params[:,2]\n",
    "\n",
    "if(0):\n",
    "    # remove the huge saturaed line at pixel 1987  & 6965 Angstrom\n",
    "    # well not 100% needed it seems we throw it away later\n",
    "    print(len(allcens))\n",
    "    ibad=np.argmin(np.abs(allcens-1987.))\n",
    "    print(ibad)\n",
    "    allcens=np.delete(allcens,ibad)\n",
    "    print(len(allcens))\n",
    "    allamps=np.delete(allamps,ibad)\n",
    "    allwids=np.delete(allwids,ibad)\n",
    "    print(allcens)\n",
    "\n",
    "    \n",
    "# Now plot the spectrum again\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(data)\n",
    "plt.plot(centroid_x_values, data[peaks], 'ro', label='Max')\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('Flux')\n",
    "plt.title('Spectrum with peaks and lines')\n",
    "plt.grid(True)\n",
    "\n",
    "# plot individual gaussian fit for each line, for check\n",
    "for i in range(num_peaks):\n",
    "    fit_params = params[i]  # Extract parameters for each Gaussian\n",
    "    gau=gaussian(xaxis, *fit_params)\n",
    "    plt.plot(xaxis, gau)#, label=f'Gaussian {i+1}')\n",
    "    plt.text(allcens[i], np.max(gau)+3000, str(i), fontsize=12, ha='center', va='center', color='blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make your list of at 5-6 lines identified from the atlas\n",
    "#(https://github.com/pocvirk/astronomical_data_reduction/blob/main/doc/line_atlas_ThAr.pdf)\n",
    "# the number of lines for our first calibration\n",
    "npixel_lambda=6\n",
    "# we build an array (6,2) pixel_lambda where:\n",
    "# - the first column is the position of a line in pixel\n",
    "# - the 2nd column is the position of that line in Angstrom in the atlas\n",
    "pixel_lambda=np.zeros((npixel_lambda,2)) \n",
    "# USAGE for guess array: column 1 => position in pixel of the peak, column2 => wavelength from atlas\n",
    "# the position of the peak is taken from array allcens (gaussian peak centroids computed just before)\n",
    "pixel_lambda[0]=[allcens[???],6182.62]\n",
    "pixel_lambda[1]=[allcens[???],6457.28]\n",
    "pixel_lambda[2]=[allcens[???],6531.34]\n",
    "pixel_lambda[3]=[allcens[???],6677.28]\n",
    "pixel_lambda[4]=[allcens[???],6752.83]\n",
    "pixel_lambda[5]=[allcens[???],6911.23]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(pixel_lambda[:,0],pixel_lambda[:,1])\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('Angstrom')\n",
    "plt.show()\n",
    "\n",
    "# well our dispersion relation looks almost linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now derive the full dispersion law as a polynomial fit through the points above\n",
    "from numpy.polynomial import chebyshev\n",
    "# Fit a Chebyshev polynomial of degree 1 (linear)\n",
    "degree = 1\n",
    "coeffs = chebyshev.chebfit(pixel_lambda[:,0], pixel_lambda[:,1], degree)\n",
    "# Evaluate the Chebyshev polynomial across xaxis\n",
    "y_fit = chebyshev.chebval(xaxis, coeffs)\n",
    "# plot the fit with our calibration points:\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(pixel_lambda[:,0],pixel_lambda[:,1])\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('Angstrom')\n",
    "plt.plot(xaxis, y_fit, label=f'Chebyshev Polynomial (Degree {degree})', color='red')\n",
    "plt.show()\n",
    "\n",
    "# thats a pretty good fit.\n",
    "# to see how good it is, we will check the residuals in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residuals are the difference between the predicted value by the polynomial and the actual position \n",
    "# of the points in the cloud of points we are trying to fit.\n",
    "import numpy as np\n",
    "npoints=len(pixel_lambda[:,1])\n",
    "predicted_wl=chebyshev.chebval(pixel_lambda[:,0],coeffs)\n",
    "atlas_wl=pixel_lambda[:,1]\n",
    "residuals = predicted_wl-atlas_wl\n",
    "\n",
    "residuals_first_iter=residuals # save for later reference and comparison\n",
    "atlas_wl_first_iter=atlas_wl # save for later reference and comparison\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.scatter(atlas_wl,residuals)\n",
    "plt.xlabel('Angstrom')\n",
    "plt.ylabel('Angstrom')\n",
    "plt.show()\n",
    "\n",
    "# display some stats about the residuals:\n",
    "print('==============================')\n",
    "print('RESIDUALS INITIAL set of lines')\n",
    "print('NLINES=',len(pixel_lambda[:,1]))\n",
    "print('RESIDUALS AVG',np.average(residuals),' Angstrom')\n",
    "print('RESIDUALS RMS',np.std(residuals), 'Angstrom')\n",
    "print('RESIDUALS RMS',np.std(residuals)/np.average(atlas_wl)*3.e5,'km/s')\n",
    "print('==============================')\n",
    "\n",
    "# Do you notice anything particular in the distribution of the residuals?\n",
    "\n",
    "# ok not bad but it has only 6 points.\n",
    "# how can we add more calibration points now that we have this first idea of what the dispersion relation\n",
    "# should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to refine our first guess of the dispersion relation, \n",
    "# we will try to match (some of) the other lines of our lamp spectrum\n",
    "# to lines from the NIST lines atlas (super accurate laboratory line list)\n",
    "# first read the NIST line list\n",
    "file_path = './linelists/ThI.csv'\n",
    "# Load the data from the CSV file\n",
    "dataThI = np.loadtxt(file_path, delimiter=',', skiprows=1)  # Skip the header row\n",
    "print(file_path,'Number of lines ',len(dataThI))\n",
    "data=dataThI\n",
    "# Split the data into 'wls' and 'rels' arrays\n",
    "NIST_wls = data[:, 0]  # Assumes wavelength is in the first column\n",
    "NIST_rels = data[:, 1]  # Assumes intensity is in the second column\n",
    "NIST_rels=NIST_rels/np.max(NIST_rels) # normalize by the max intensity for convenience\n",
    "\n",
    "# just have a look at this linelist:\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.scatter(NIST_wls,NIST_rels,marker='x',alpha=0.3)\n",
    "plt.xlabel('Angstrom')\n",
    "plt.ylabel('Relative Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thats a lot of faint lines!\n",
    "# select only the brightest of lines from the NIST linelist\n",
    "ind=np.where(NIST_rels>=0.2)[0]\n",
    "NIST_wls=NIST_wls[ind]\n",
    "NIST_rels=NIST_rels[ind]\n",
    "print('Number of NIST lines kept',len(ind))\n",
    "\n",
    "# prepare tables, the size of the number of peaks we kept from the lamp (num_peaks)\n",
    "match = np.zeros(num_peaks) # the match vector: 0 means there is no match for that line\n",
    "predicted_wl=np.zeros(num_peaks) # wavelength predicted by our polynomial calibration\n",
    "atlas_wl=np.zeros(num_peaks)     # wavelength of the match in the atlas\n",
    "residuals = np.zeros(num_peaks)\n",
    "\n",
    "# Max delta allowed for a match\n",
    "maxdelta=0.2 # Angstrom \n",
    "\n",
    "# Check if in our lamp lines, there can be a match in the NIST line list\n",
    "for i in range(num_peaks):\n",
    "    predicted_wl[i]=chebyshev.chebval(allcens[i],coeffs) # predicted wavelength for lamp line\n",
    "    imin=np.argmin(np.abs(predicted_wl[i]-NIST_wls)) # index of the closest line in the NIST atlas line list\n",
    "    residuals[i]=(predicted_wl[i]-NIST_wls[imin]) # distance (Angstrom) between the closest NIST line and our lamp line\n",
    "    atlas_wl[i]=NIST_wls[imin] # NIST wavelength for that line\n",
    "    if(np.abs(residuals[i])<maxdelta): # we keep that match only if the difference in angstrom < maxdelta\n",
    "        match[i]=imin\n",
    "\n",
    "# plot the new matched lines on top of the lines we had before:\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(pixel_lambda[:,0],pixel_lambda[:,1],label='first iteration')\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('Angstrom')\n",
    "plt.plot(xaxis, y_fit, label=f'Chebyshev Polynomial (Degree {degree})', color='red')\n",
    "ind=np.where(match!=0)[0] # select only matches\n",
    "plt.scatter(allcens[ind],atlas_wl[ind],alpha=0.3,label='new matches')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# this looks nice but is it any good?\n",
    "# to gain insight, lets look at the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the residuals\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(atlas_wl_first_iter,residuals_first_iter,label='first iteration')\n",
    "ind=np.where(match!=0)[0]\n",
    "plt.scatter(atlas_wl[ind],residuals[ind],alpha=0.3,label='new matches, NIST')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Residuals')\n",
    "plt.xlabel('Angstrom')\n",
    "plt.ylabel('Angstrom')\n",
    "plt.show()\n",
    "print('==============================')\n",
    "print('RESIDUALS INITIAL set of lines')\n",
    "print('NLINES=',len(pixel_lambda[:,1]))\n",
    "print('RESIDUALS AVG',np.average(residuals_first_iter))\n",
    "print('RESIDUALS RMS',np.std(residuals_first_iter))\n",
    "print('RESIDUALS RMS',(np.std(residuals_first_iter)/np.average(atlas_wl_first_iter)*3.e5),'km/s')\n",
    "print('==============================')\n",
    "print('RESIDUALS NEW set of lines')\n",
    "print('NLINES=',len(ind))\n",
    "print('RESIDUALS AVG',np.average(residuals[ind]))\n",
    "print('RESIDUALS RMS',np.std(residuals[ind]))\n",
    "print('RESIDUALS RMS',(np.std(residuals[ind])/np.average(atlas_wl[ind]))*3.e5,'km/s')\n",
    "print('===============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try that again now that we have these new additional lines\n",
    "new_pixel_lambda=np.zeros((len(ind),2))\n",
    "new_pixel_lambda[:,0]=allcens[ind]\n",
    "new_pixel_lambda[:,1]=atlas_wl[ind]\n",
    "pixel_lambda=new_pixel_lambda\n",
    "\n",
    "degree=3\n",
    "coeffs = chebyshev.chebfit(pixel_lambda[:,0], pixel_lambda[:,1], degree)\n",
    "print(coeffs)\n",
    "# Evaluate the Chebyshev polynomial at the x_range\n",
    "y_fit = chebyshev.chebval(xaxis, coeffs)\n",
    "predicted=chebyshev.chebval(pixel_lambda[:,0], coeffs)\n",
    "plt.figure(figsize=(10,5))\n",
    "residuals=predicted-new_pixel_lambda[:,1]\n",
    "plt.scatter(pixel_lambda[:,1],residuals,label='second iteration')\n",
    "plt.ylabel('Angstrom')\n",
    "plt.xlabel('Angstrom')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('==============================')\n",
    "print('RESIDUALS NEW set of lines')\n",
    "print('NLINES=',len(ind))\n",
    "print('DEGREE=',degree)\n",
    "print('RESIDUALS AVG',np.average(residuals))\n",
    "print('RESIDUALS RMS',np.std(residuals))\n",
    "print('RESIDUALS RMS',(np.std(residuals))/np.average(pixel_lambda[:,1])*3.e5,'km/s')\n",
    "print('==============================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So our FINAL calibration result is the line below: \n",
    "# We can build the full wavelengths axis of our observed spectra by evaluating the polynomial\n",
    "wavelengths=chebyshev.chebval(xaxis, coeffs)\n",
    "# and save it to a file to retrieve later for spectral analysis:\n",
    "calib_file='../../data/t152_spectro/lamp_thar/calib/calib.dat'\n",
    "wavelengths.tofile(calib_file)\n",
    "# NB: here we are not storing the coeffs of the polynomial but the whole 2142 array representing\n",
    "# the wavelengths in Angstrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can retrieve the wavelengths axis like this:\n",
    "wavelengths=np.fromfile(calib_file)\n",
    "# With this wavelength axis, I can finally plot any observed spectrum with a physical wavelenth axis:\n",
    "file='../../data/t152_spectro/M82/p67532.fits'\n",
    "xaxis,data,header=read_raw_spectrum(file,get_header=1)\n",
    "plt.figure(figsize=(9,5))\n",
    "# we can now replace the x axis with our wavelengths\n",
    "plt.plot(wavelengths,data)\n",
    "plt.ylabel('ADU')\n",
    "plt.xlabel('Angstrom')\n",
    "plt.show()\n",
    "\n",
    "print(repr(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do we have here???\n",
    "# any idea what those lines could be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================\n",
    "# END OF NOTEBOOK\n",
    "# =================\n",
    "## beyond this is fossil code\n",
    "## to be cleaned\n",
    "## read at your own risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replot the lamp spectrum using the new calibration\n",
    "# Plot the spectrum and mark the centroids\n",
    "fits_file = '../data/t152_spectro/lamp_thar/p67507.fits'\n",
    "xaxis1,data1=read_raw_spectrum(fits_file)\n",
    "wavelengths=chebyshev.chebval(xaxis1, coeffs)\n",
    "\n",
    "\n",
    "iraf_file='../lamp_thar/thar_lambda.fits'\n",
    "#xaxis,data=read_raw_spectrum(iraf_file)\n",
    "wave,data_iraf=read_calibrated_spectrum(iraf_file)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "# ok so which lines did we actually end up using?\n",
    "nguess=(len(guess))\n",
    "for i in range(nguess):\n",
    "    print(guess[i,1])\n",
    "    plt.plot(np.full(100,guess[i,1]),np.linspace(0.,60000.,100),lw=1)\n",
    "\n",
    "\n",
    "plt.plot(wavelengths,data1,label='python_calib',lw=1,color='r')\n",
    "plt.plot(wave,data_iraf,label='iraf_calib',lw=1,color='b')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linspace(0.,60000.,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BELOW IS INTERESTING BUT NOT ESSENTIAL CODE\n",
    "# TO KEEP OUT OF CURIOSITY\n",
    "# A VERY DARING THOUGH NOT VERY SUCCESSFUL ATTEMPT TO AUTOMATICALLY MATCH AT LEAST A FEW LINES BASED SOLELY ON NIST INFORMATION!\n",
    "# it works for a few lines but not across the whole spectrum\n",
    "vals=['obs','NIST']\n",
    "# select matching triplets\n",
    "deltalwl=0.002\n",
    "deltalF=13.5\n",
    "relax_factor=0.9\n",
    "nvals=len(vals)\n",
    "x1=[]\n",
    "y1=[]\n",
    "x2=[]\n",
    "y2=[]\n",
    "# Create a 2D scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(nvals):\n",
    "\n",
    "    \n",
    "    if(i==0):\n",
    "        # Plot the lamp spectrum ratios\n",
    "        obs_wls=allcens\n",
    "        obs_amps=allamps/np.max(obs_amps)\n",
    "        spectroscopic_lines = obs_wls\n",
    "        amps=obs_amps\n",
    "        col='r'\n",
    "        leg='obs'\n",
    "        al=0.3\n",
    "        m='o'\n",
    "        nlines_obs=len(obs_wls)\n",
    "        \n",
    "    if(i==1):\n",
    "        al=1.\n",
    "        col='b'\n",
    "        leg='NIST'\n",
    "        m='+'\n",
    "        dataThI=[]\n",
    "        dataArI=[]\n",
    "        dataArII=[]\n",
    "        dataThII=[]\n",
    "        data=[]\n",
    "        # Plot the NIST file ratios\n",
    "        # Define the file path\n",
    "        if(1):\n",
    "            file_path = 'ThI.csv'\n",
    "            # Load the data from the CSV file\n",
    "            dataThI = np.loadtxt(file_path, delimiter=',', skiprows=1)  # Skip the header row\n",
    "            print(file_path,len(dataThI))\n",
    "        \n",
    "        if(1):\n",
    "            file_path = 'ArI.csv'\n",
    "            # Load the data from the CSV file\n",
    "            dataArI = np.loadtxt(file_path, delimiter=',', skiprows=1)  # Skip the header row\n",
    "            print(file_path,len(dataArI))\n",
    "\n",
    "        file_path = 'ArII.csv'\n",
    "        # Load the data from the CSV file\n",
    "        dataArII = np.loadtxt(file_path, delimiter=',', skiprows=1)  # Skip the header row\n",
    "        print(file_path,len(dataArII))\n",
    "        file_path = 'ThII.csv'\n",
    "        # Load the data from the CSV file\n",
    "        dataThII = np.loadtxt(file_path, delimiter=',', skiprows=1)  # Skip the header row\n",
    "        print(file_path,len(dataThII))\n",
    "        \n",
    "        \n",
    "#        data=np.concatenate((dataThI,dataArI,dataArII,dataThII),axis=0)\n",
    "        data=np.concatenate((dataThII,dataArII,dataArI,dataThI),axis=0)\n",
    "        print(len(data))\n",
    "        \n",
    "        # Split the data into 'wls' and 'rels' arrays\n",
    "        NIST_wls = data[:, 0]  # Assumes wavelength is in the first column\n",
    "        NIST_rels = data[:, 1]  # Assumes intensity is in the second column\n",
    "        NIST_rels=NIST_rels/np.max(NIST_rels)\n",
    "        # make sure we have the same number of lines in NIST as in OBS\n",
    "        sNIST_rels=np.sort(NIST_rels)[::-1]\n",
    "        relmin=sNIST_rels[nlines_obs-1]\n",
    "        # or maybe relax taht constraint by some factor:\n",
    "        ind=np.where(NIST_rels>=relmin*relax_factor)[0]\n",
    "        NIST_wls=NIST_wls[ind]\n",
    "        NIST_rels=NIST_rels[ind]\n",
    "\n",
    "        spectroscopic_lines = NIST_wls\n",
    "        amps=NIST_rels\n",
    "\n",
    "\n",
    "    print('Number of lines ',vals[i],len(spectroscopic_lines))\n",
    "\n",
    "\n",
    "    # Calculate the ratios lambda1/lambda2 and lambda2/lambda3\n",
    "    \n",
    "    deltas_1_2 = [l2 - l1 for l1, l2 in zip(spectroscopic_lines[:-1], spectroscopic_lines[1:])]\n",
    "    deltas_2_3 = [l3 - l2 for l2, l3 in zip(spectroscopic_lines[1:], spectroscopic_lines[2:])]\n",
    "    deltas_1_3 = [l3 - l1 for l1, l3 in zip(spectroscopic_lines[:-1], spectroscopic_lines[2:])]\n",
    "    avgamps= [ np.average([a1,a2,a3]) for a1, a2, a3 in zip(amps[:-1], amps[1:],amps[2:])]\n",
    "    maxamps= [ np.max([a1,a2,a3]) for a1, a2, a3 in zip(amps[:-1], amps[1:],amps[2:])]\n",
    "    minamps= [ np.min([a1,a2,a3]) for a1, a2, a3 in zip(amps[:-1], amps[1:],amps[2:])]\n",
    "\n",
    "\n",
    "\n",
    "#    print(len(deltas_1_2))\n",
    "#    print(len(deltas_1_3))\n",
    "#    print(len(avgamps))\n",
    "\n",
    "    # Ensure both lists have the same size\n",
    "    min_size = min(len(deltas_1_2), len(deltas_2_3),len(deltas_1_3),len(avgamps))\n",
    "    deltas_1_2 = deltas_1_2[:min_size]\n",
    "    deltas_2_3 = deltas_2_3[:min_size]\n",
    "    deltas_1_3 = deltas_1_3[:min_size]\n",
    "    ratios_1_2=np.array(deltas_1_2)/np.array(deltas_1_3)\n",
    "    ratios_2_3=np.array(deltas_2_3)/np.array(deltas_1_3)\n",
    "    ratios_1_2_3=np.array(deltas_1_2)/np.array(deltas_2_3)\n",
    "    minmaxampratio=np.array(maxamps)/np.array(minamps)\n",
    "\n",
    "    if(i==0):\n",
    "        x1=np.log(ratios_1_2_3)\n",
    "        y1=np.log(minmaxampratio)\n",
    "        \n",
    "    if(i==1):\n",
    "        x2=np.log(ratios_1_2_3)\n",
    "        y2=np.log(minmaxampratio)\n",
    "    \n",
    "    plt.scatter(np.log(ratios_1_2_3), np.log(minmaxampratio), c=col,marker=m, label=leg,alpha=al)\n",
    "    \n",
    "#plt.colorbar()\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('$(\\lambda_2-\\lambda_1)/(\\lambda_3-\\lambda_2)$', fontsize=14)\n",
    "plt.ylabel('$F_{max}/F_{min}$', fontsize=14)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "\n",
    "# Add a grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.title('Spectroscopic Line Ratios')\n",
    "#plt.show()\n",
    "\n",
    "deltax=deltalwl\n",
    "deltay=deltalF\n",
    "\n",
    "# Initialize a list to store pairs of points that satisfy the conditions\n",
    "satisfying_pairs = []\n",
    "matches=[] # 0 is obs, 1 is NIST\n",
    "\n",
    "# Loop through each pair of points from (x1, y1) and (x2, y2)\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        if np.abs(x1[i] - x2[j]) < deltax and np.abs(y1[i] - y2[j]) < deltay:\n",
    "            satisfying_pairs.append((x1[i], y1[i], x2[j], y2[j]))\n",
    "            matches.append((i,j))\n",
    "\n",
    "\n",
    "            \n",
    "# build the final line list obs vs NIST\n",
    "            \n",
    "for pair in satisfying_pairs:\n",
    "    x1, y1, x2, y2 = pair\n",
    "#    plt.scatter(x1,y1,alpha=0.)\n",
    "#    plt.scatter(x2,y2)\n",
    "    plt.plot([x1,x2],[y1,y2])\n",
    "    print(x1,x2,y1,y2)\n",
    "#    print(x1)\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot obs pixels vs obs line\n",
    "print(matches)\n",
    "nm=len(matches)\n",
    "lobs1=np.zeros(nm)\n",
    "lobs2=np.zeros(nm)\n",
    "lobs3=np.zeros(nm)\n",
    "\n",
    "lnist1=np.zeros(nm)\n",
    "lnist2=np.zeros(nm)\n",
    "lnist3=np.zeros(nm)\n",
    "\n",
    "for i in range(nm):\n",
    "    j,k=matches[i]\n",
    "#    print(j,k)\n",
    "    lobs1[i]=obs_wls[:-1][j]\n",
    "    lobs2[i]=obs_wls[1:][j]\n",
    "    lobs3[i]=obs_wls[2:][j]\n",
    "#    print(np.log((lobs2[i]-lobs1[i])/(lobs3[i]-lobs2[i])))\n",
    "    lnist1[i]=NIST_wls[:-1][k]\n",
    "    lnist2[i]=NIST_wls[1:][k]\n",
    "    lnist3[i]=NIST_wls[2:][k]\n",
    "#    print(np.log((lnist2[i]-lnist1[i])/(lnist3[i]-lnist2[i])))\n",
    "\n",
    "lobs=[]\n",
    "lnist=[]\n",
    "lobs=np.append(lobs,[lobs1,lobs2,lobs3])\n",
    "lnist=np.append(lnist,[lnist1,lnist2,lnist3])    \n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(lobs,lnist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
